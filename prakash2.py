# -*- coding: utf-8 -*-
"""prakash2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15GJlEi04utSZKDu-5QM9mP6fpz9PdOJW
"""

import requests
from bs4 import BeautifulSoup

BASE_URL = "https://www.amazon.in"
SEARCH_TERM = "bags"
PAGES_TO_SCRAPE = 20
MAX_PRODUCTS = 200  # Maximum number of products to scrape

def get_product_data(product_div):
    # Extract product URL, name, price, rating, and reviews
    product_link = product_div.find("a", class_="a-link-normal")
    if product_link:
        product_url = BASE_URL + product_link["href"]
        product_name_elem = product_link.find("span", class_="a-text-normal")
        product_name = product_name_elem.get_text(strip=True) if product_name_elem else "N/A"
    else:
        product_url = "N/A"
        product_name = "N/A"

    price_elem = product_div.find("span", class_="a-offscreen")
    product_price = price_elem.get_text(strip=True) if price_elem else "N/A"

    rating_elem = product_div.find("span", class_="a-icon-alt")
    product_rating = rating_elem.get_text(strip=True) if rating_elem else "N/A"

    num_reviews_elem = product_div.find("span", class_="a-size-base")
    num_reviews = num_reviews_elem.get_text(strip=True) if num_reviews_elem else "N/A"

    return {
        "url": product_url,
        "name": product_name,
        "price": product_price,
        "rating": product_rating,
        "reviews": num_reviews,
    }

def get_product_details(product_url):
    if product_url == "N/A":
        return {"description": "N/A", "asin": "N/A", "product_description": "N/A", "manufacturer": "N/A"}

    response = requests.get(product_url)
    soup = BeautifulSoup(response.content, "html.parser")

    # Extract additional details (modify selectors as needed)
    description_elem = soup.find("div", id="productDescription")
    description = description_elem.get_text(strip=True) if description_elem else "N/A"

    asin_elem = soup.find("th", string="ASIN")
    asin = asin_elem.find_next("td").get_text(strip=True) if asin_elem else "N/A"

    product_desc_elem = soup.find("div", id="productDescription")
    product_description = product_desc_elem.get_text(strip=True) if product_desc_elem else "N/A"

    manufacturer_elem = soup.find("a", id="bylineInfo")
    manufacturer = manufacturer_elem.get_text(strip=True) if manufacturer_elem else "N/A"

    return {
        "description": description,
        "asin": asin,
        "product_description": product_description,
        "manufacturer": manufacturer,
    }

def scrape_amazon_products():
    all_products = []

    for page in range(1, PAGES_TO_SCRAPE + 1):
        url = f"https://www.amazon.in/s?k={SEARCH_TERM}&page={page}"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, "html.parser")
        product_divs = soup.find_all("div", class_="s-result-item")

        for product_div in product_divs:
            product_data = get_product_data(product_div)
            product_url = product_data["url"]

            product_details = get_product_details(product_url)
            product_data.update(product_details)  # Merge product data and details

            all_products.append(product_data)

            if len(all_products) >= MAX_PRODUCTS:
                break

        if len(all_products) >= MAX_PRODUCTS:
            break

    return all_products

if __name__ == "__main__":
    products = scrape_amazon_products()

    # Print scraped data
    for product in products:
        print("Product URL:", product["url"])
        print("Product Name:", product["name"])
        print("Product Price:", product["price"])
        print("Product Rating:", product["rating"])
        print("Number of Reviews:", product["reviews"])
        print("Description:", product["description"])
        print("ASIN:", product["asin"])
        print("Product Description:", product["product_description"])
        print("Manufacturer:", product["manufacturer"])
        print("=" * 50)

